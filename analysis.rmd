---
title: "Human Activity Recognition Report"
author: "Joshika"
output:
  html_document:
    toc: true
    theme: journal
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(caret)
library(randomForest)
library(dplyr)
library(ggplot2)
library(knitr)
```

## Introduction

This report aims to predict the manner in which subjects performed barbell lifts using accelerometer data from a wearable device. The data were collected using devices like Jawbone Up, Nike FuelBand, and Fitbit, which are commonly used in the quantified self movement. Participants were asked to perform barbell lifts correctly and incorrectly in five different ways. Our goal is to predict the quality of performance based on sensor data.

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit, it is now possible to collect large amounts of personal activity data. These devices are part of the quantified self movement. However, while people often measure how much activity they do, they rarely measure how well it is done. In this project, data from accelerometers on the belt, forearm, arm, and dumbbell of six participants were used while they performed barbell lifts in five different ways.

More details: [Weight Lifting Exercise Dataset](http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har)

## Data Loading and Cleaning

```{r}
# Read training and test data
training <- read.csv("pml-training.csv", na.strings = c("NA", "", "#DIV/0!"))
testing <- read.csv("pml-testing.csv", na.strings = c("NA", "", "#DIV/0!"))

# Remove non-predictive columns
remove_cols <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- training[, !(names(training) %in% remove_cols)]
testing <- testing[, !(names(testing) %in% remove_cols)]

# Remove columns with mostly NAs
na_count <- sapply(training, function(x) sum(is.na(x)))
training <- training[, na_count < nrow(training) * 0.9]

# Keep only matching columns in test set
testing <- testing[, names(testing) %in% names(training)]
```

## Model Training

```{r}
# Convert outcome variable to factor
training$classe <- as.factor(training$classe)

# Split data
set.seed(123)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
train_data <- training[inTrain, ]
valid_data <- training[-inTrain, ]

# Train model
ctrl <- trainControl(method = "cv", number = 3)
model_rf <- train(classe ~ ., data = train_data, method = "rf", trControl = ctrl)
```

## Model Evaluation

```{r}
pred_valid <- predict(model_rf, valid_data)
conf_mat <- confusionMatrix(pred_valid, valid_data$classe)
conf_mat
```

## Justification of Model Choice

We chose the **Random Forest** algorithm for its high accuracy, robustness to noise, built-in feature selection, and strong generalization. It is well-suited for high-dimensional data like the one used in this project.

## Cross-validation Explanation

We used **3-fold cross-validation** to reduce overfitting and ensure our model generalizes well to unseen data. This means the model is trained and validated across three different partitions of the training data.

## Expected Out-of-Sample Error

The model achieved an accuracy of approximately `r round(conf_mat$overall['Accuracy'], 4)`, implying an estimated out-of-sample error of:

```{r}
1 - conf_mat$overall['Accuracy']
```

## Final Predictions

```{r}
final_predictions <- predict(model_rf, testing)

# Display predictions in a clean table
results <- data.frame(Problem_ID = 1:20, Prediction = final_predictions)
kable(results, caption = "Final Predictions on 20 Test Cases")

```

## Submission of Predictions

```{r}
# Write final predictions to 20 text files
pml_write_files <- function(x) {
  for (i in 1:length(x)) {
    filename <- paste0("problem_id_", i, ".txt")
    write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, col.names = FALSE)
    cat(paste0("✔️ File created: ", filename, "<br>"))
  }
}
pml_write_files(final_predictions)
```

## Data Source

The data for this project come from: [PUC-Rio HAR Dataset](http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har).

Please cite them if you use this document for other purposes.

## Conclusion

We developed a highly accurate Random Forest classifier to predict barbell lifting quality using accelerometer data. With an out-of-sample error under 1%, our model demonstrates strong performance and generalizability.
